{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbpE_MJH3n3h",
        "outputId": "dba528ee-6a38-4ef3-a753-1c97ddb10432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0vGfiIpLho1"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU6xy-F_LlLN"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import random as rd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "from scipy.io import loadmat\n",
        "import copy as cp\n",
        "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, average_precision_score\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I7kE9IvUZc7"
      },
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID3YRTEuLeVR"
      },
      "outputs": [],
      "source": [
        "def load_data(data):\n",
        "\tprefix = '/content/drive/MyDrive/DOAN/'\n",
        "\tif(data == 'YelpChi'):\n",
        "\t\tdata_file = loadmat(prefix + 'YelpChi.mat')\n",
        "\t\twith open(prefix + 'yelp_homo_adjlists.pickle', 'rb') as file:\n",
        "\t\t\thomo = pickle.load(file)\n",
        "\t\t\tfile.close()\n",
        "\t\twith open(prefix + 'yelp_rur_adjlists.pickle', 'rb') as file:\n",
        "\t\t\trelation1 = pickle.load(file)\n",
        "\t\t\tfile.close()\n",
        "\t\twith open(prefix + 'yelp_rtr_adjlists.pickle', 'rb') as file:\n",
        "\t\t\trelation2 = pickle.load(file)\n",
        "\t\t\tfile.close()\n",
        "\t\twith open(prefix + 'yelp_rsr_adjlists.pickle', 'rb') as file:\n",
        "\t\t\trelation3 = pickle.load(file)\n",
        "\t\t\tfile.close()\n",
        "\tlabels = data_file['label'].flatten()\n",
        "\tfeat_data = data_file['features'].todense().A\n",
        "\treturn [homo, relation1, relation2, relation3], feat_data, labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Processing Function"
      ],
      "metadata": {
        "id": "nbT_33esyIw9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbrVD8DDLt3T"
      },
      "outputs": [],
      "source": [
        "def normalize(mx):\n",
        "\trowsum = np.array(mx.sum(1)) + 0.01\n",
        "\tr_inv = np.power(rowsum, -1).flatten()\n",
        "\tr_inv[np.isinf(r_inv)] = 0.\n",
        "\tr_mat_inv = sp.diags(r_inv)\n",
        "\tmx = r_mat_inv.dot(mx)\n",
        "\treturn mx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J14esRx4LwhT"
      },
      "outputs": [],
      "source": [
        "def sparse_to_adjlist(sp_matrix, filename):\n",
        "\thomo_adj = sp_matrix + sp.eye(sp_matrix.shape[0])\n",
        "\tadj_lists = defaultdict(set)\n",
        "\tedges = homo_adj.nonzero()\n",
        "\tfor index, node in enumerate(edges[0]):\n",
        "\t\tadj_lists[node].add(edges[1][index])\n",
        "\t\tadj_lists[edges[1][index]].add(node)\n",
        "\twith open(filename, 'wb') as file:\n",
        "\t\tpickle.dump(adj_lists, file)\n",
        "\tfile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkwJxS6PLysg"
      },
      "outputs": [],
      "source": [
        "def pos_neg_split(nodes, labels):\n",
        "\tpos_nodes = []\n",
        "\tneg_nodes = cp.deepcopy(nodes)\n",
        "\taux_nodes = cp.deepcopy(nodes)\n",
        "\tfor idx, label in enumerate(labels):\n",
        "\t\tif label == 1:\n",
        "\t\t\tpos_nodes.append(aux_nodes[idx])\n",
        "\t\t\tneg_nodes.remove(aux_nodes[idx])\n",
        "\n",
        "\treturn pos_nodes, neg_nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nwed3-xKL1LR"
      },
      "outputs": [],
      "source": [
        "def undersample(pos_nodes, neg_nodes, scale=1):\n",
        "\n",
        "\taux_nodes = cp.deepcopy(neg_nodes)\n",
        "\taux_nodes = rd.sample(aux_nodes, k=int(len(pos_nodes)*scale))\n",
        "\tbatch_nodes = pos_nodes + aux_nodes\n",
        "\n",
        "\treturn batch_nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAFbme_SMbYq"
      },
      "source": [
        "## 3. CARE GNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G-8x6DzMCLg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "\n",
        "\n",
        "class OneLayerCARE(nn.Module):\n",
        "\n",
        "\tdef __init__(self, num_classes, inter1, lambda_1):\n",
        "\t\tsuper(OneLayerCARE, self).__init__()\n",
        "\t\tself.inter1 = inter1\n",
        "\t\tself.xent = nn.CrossEntropyLoss()\n",
        "\n",
        "\t\tself.weight = nn.Parameter(torch.FloatTensor(inter1.embed_dim, num_classes))\n",
        "\t\tinit.xavier_uniform_(self.weight)\n",
        "\t\tself.lambda_1 = lambda_1\n",
        "\n",
        "\tdef forward(self, nodes, labels, train_flag=True):\n",
        "\t\tembeds1, label_scores = self.inter1(nodes, labels, train_flag)\n",
        "\t\tscores = torch.mm(embeds1, self.weight)\n",
        "\t\treturn scores, label_scores\n",
        "\n",
        "\tdef to_prob(self, nodes, labels, train_flag=True):\n",
        "\t\tgnn_scores, label_scores = self.forward(nodes, labels, train_flag)\n",
        "\t\tgnn_prob = nn.functional.softmax(gnn_scores, dim=1)\n",
        "\t\tlabel_prob = nn.functional.softmax(label_scores, dim=1)\n",
        "\t\treturn gnn_prob, label_prob\n",
        "\n",
        "\tdef loss(self, nodes, labels, train_flag=True):\n",
        "\t\tgnn_scores, label_scores = self.forward(nodes, labels, train_flag)\n",
        "\t\tlabel_loss = self.xent(label_scores, labels.squeeze())\n",
        "\t\tgnn_loss = self.xent(gnn_scores, labels.squeeze())\n",
        "\t\tfinal_loss = gnn_loss + self.lambda_1 * label_loss\n",
        "\t\treturn final_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DX5rclAuM7fq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "from operator import itemgetter\n",
        "import math\n",
        "\n",
        "class InterAgg(nn.Module):\n",
        "\n",
        "\tdef __init__(self, features, feature_dim,\n",
        "\t\t\t\t embed_dim, adj_lists, intraggs,\n",
        "\t\t\t\t inter='GNN', step_size=0.02, cuda=True):\n",
        "\t\tsuper(InterAgg, self).__init__()\n",
        "\n",
        "\t\tself.features = features\n",
        "\t\tself.dropout = 0.6\n",
        "\t\tself.adj_lists = adj_lists\n",
        "\t\tself.intra_agg1 = intraggs[0]\n",
        "\t\tself.intra_agg2 = intraggs[1]\n",
        "\t\tself.intra_agg3 = intraggs[2]\n",
        "\t\tself.embed_dim = embed_dim\n",
        "\t\tself.feat_dim = feature_dim\n",
        "\t\tself.inter = inter\n",
        "\t\tself.step_size = step_size\n",
        "\t\tself.cuda = cuda\n",
        "\t\tself.intra_agg1.cuda = cuda\n",
        "\t\tself.intra_agg2.cuda = cuda\n",
        "\t\tself.intra_agg3.cuda = cuda\n",
        "\n",
        "\t\t# RL condition flag\n",
        "\t\tself.RL = True\n",
        "\n",
        "\t\t# number of batches for current epoch, assigned during training\n",
        "\t\tself.batch_num = 0\n",
        "\n",
        "\t\t# initial filtering thresholds\n",
        "\t\tself.thresholds = [0.5, 0.5, 0.5]\n",
        "\n",
        "\t\t# the activation function used by attention mechanism\n",
        "\t\tself.leakyrelu = nn.LeakyReLU(0.2)\n",
        "\n",
        "\t\t# parameter used to transform node embeddings before inter-relation aggregation\n",
        "\t\tself.weight = nn.Parameter(torch.FloatTensor(self.feat_dim, self.embed_dim))\n",
        "\t\tinit.xavier_uniform_(self.weight)\n",
        "\n",
        "\t\t# weight parameter for each relation used by CARE-Weight\n",
        "\t\tself.alpha = nn.Parameter(torch.FloatTensor(self.embed_dim, 3))\n",
        "\t\tinit.xavier_uniform_(self.alpha)\n",
        "\n",
        "\t\t# parameters used by attention layer\n",
        "\t\tself.a = nn.Parameter(torch.FloatTensor(2 * self.embed_dim, 1))\n",
        "\t\tinit.xavier_uniform_(self.a)\n",
        "\n",
        "\t\t# label predictor for similarity measure\n",
        "\t\tself.label_clf = nn.Linear(self.feat_dim, 2)\n",
        "\n",
        "\t\t# initialize the parameter logs\n",
        "\t\tself.weights_log = []\n",
        "\t\tself.thresholds_log = [self.thresholds]\n",
        "\t\tself.relation_score_log = []\n",
        "\n",
        "\tdef forward(self, nodes, labels, train_flag=True):\n",
        "\n",
        "\t\t# extract 1-hop neighbor ids from adj lists of each single-relation graph\n",
        "\t\tto_neighs = []\n",
        "\t\tfor adj_list in self.adj_lists:\n",
        "\t\t\tto_neighs.append([set(adj_list[int(node)]) for node in nodes])\n",
        "\n",
        "\t\t# find unique nodes and their neighbors used in current batch\n",
        "\t\tunique_nodes = set.union(set.union(*to_neighs[0]), set.union(*to_neighs[1]),\n",
        "\t\t\t\t\t\t\t\t set.union(*to_neighs[2], set(nodes)))\n",
        "\n",
        "\t\t# calculate label-aware scores\n",
        "\t\tif self.cuda:\n",
        "\t\t\tbatch_features = self.features(torch.cuda.LongTensor(list(unique_nodes)))\n",
        "\t\telse:\n",
        "\t\t\tbatch_features = self.features(torch.LongTensor(list(unique_nodes)))\n",
        "\t\tbatch_scores = self.label_clf(batch_features)\n",
        "\t\tid_mapping = {node_id: index for node_id, index in zip(unique_nodes, range(len(unique_nodes)))}\n",
        "\n",
        "\t\t# the label-aware scores for current batch of nodes\n",
        "\t\tcenter_scores = batch_scores[itemgetter(*nodes)(id_mapping), :]\n",
        "\n",
        "\t\t# get neighbor node id list for each batch node and relation\n",
        "\t\tr1_list = [list(to_neigh) for to_neigh in to_neighs[0]]\n",
        "\t\tr2_list = [list(to_neigh) for to_neigh in to_neighs[1]]\n",
        "\t\tr3_list = [list(to_neigh) for to_neigh in to_neighs[2]]\n",
        "\n",
        "\t\t# assign label-aware scores to neighbor nodes for each batch node and relation\n",
        "\t\tr1_scores = [batch_scores[itemgetter(*to_neigh)(id_mapping), :].view(-1, 2) for to_neigh in r1_list]\n",
        "\t\tr2_scores = [batch_scores[itemgetter(*to_neigh)(id_mapping), :].view(-1, 2) for to_neigh in r2_list]\n",
        "\t\tr3_scores = [batch_scores[itemgetter(*to_neigh)(id_mapping), :].view(-1, 2) for to_neigh in r3_list]\n",
        "\n",
        "\t\t# count the number of neighbors kept for aggregation for each batch node and relation\n",
        "\t\tr1_sample_num_list = [math.ceil(len(neighs) * self.thresholds[0]) for neighs in r1_list]\n",
        "\t\tr2_sample_num_list = [math.ceil(len(neighs) * self.thresholds[1]) for neighs in r2_list]\n",
        "\t\tr3_sample_num_list = [math.ceil(len(neighs) * self.thresholds[2]) for neighs in r3_list]\n",
        "\n",
        "\t\t# intra-aggregation steps for each relation\n",
        "\t\t# Eq. (8) in the paper\n",
        "\t\tr1_feats, r1_scores = self.intra_agg1.forward(nodes, r1_list, center_scores, r1_scores, r1_sample_num_list)\n",
        "\t\tr2_feats, r2_scores = self.intra_agg2.forward(nodes, r2_list, center_scores, r2_scores, r2_sample_num_list)\n",
        "\t\tr3_feats, r3_scores = self.intra_agg3.forward(nodes, r3_list, center_scores, r3_scores, r3_sample_num_list)\n",
        "\n",
        "\t\t# concat the intra-aggregated embeddings from each relation\n",
        "\t\tneigh_feats = torch.cat((r1_feats, r2_feats, r3_feats), dim=0)\n",
        "\n",
        "\t\t# get features or embeddings for batch nodes\n",
        "\t\tif self.cuda and isinstance(nodes, list):\n",
        "\t\t\tindex = torch.LongTensor(nodes).cuda()\n",
        "\t\telse:\n",
        "\t\t\tindex = torch.LongTensor(nodes)\n",
        "\t\tself_feats = self.features(index)\n",
        "\n",
        "\t\t# number of nodes in a batch\n",
        "\t\tn = len(nodes)\n",
        "\n",
        "\t\t# inter-relation aggregation steps\n",
        "\t\t# Eq. (9) in the paper\n",
        "\t\tif self.inter == 'Att':\n",
        "\t\t\t# 1) CARE-Att Inter-relation Aggregator\n",
        "\t\t\tcombined, attention = att_inter_agg(len(self.adj_lists), self.leakyrelu, self_feats, neigh_feats, self.embed_dim,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tself.weight, self.a, n, self.dropout, self.training, self.cuda)\n",
        "\t\telif self.inter == 'Weight':\n",
        "\t\t\t# 2) CARE-Weight Inter-relation Aggregator\n",
        "\t\t\tcombined = weight_inter_agg(len(self.adj_lists), self_feats, neigh_feats, self.embed_dim, self.weight, self.alpha, n, self.cuda)\n",
        "\t\t\tgem_weights = F.softmax(torch.sum(self.alpha, dim=0), dim=0).tolist()\n",
        "\t\t\tif train_flag:\n",
        "\t\t\t\tprint(f'Weights: {gem_weights}')\n",
        "\t\telif self.inter == 'Mean':\n",
        "\t\t\t# 3) CARE-Mean Inter-relation Aggregator\n",
        "\t\t\tcombined = mean_inter_agg(len(self.adj_lists), self_feats, neigh_feats, self.embed_dim, self.weight, n, self.cuda)\n",
        "\t\telif self.inter == 'GNN':\n",
        "\t\t\t# 4) CARE-GNN Inter-relation Aggregator\n",
        "\t\t\tcombined = threshold_inter_agg(len(self.adj_lists), self_feats, neigh_feats, self.embed_dim, self.weight, self.thresholds, n, self.cuda)\n",
        "\n",
        "\t\t# the reinforcement learning module\n",
        "\t\tif self.RL and train_flag:\n",
        "\t\t\trelation_scores, rewards, thresholds, stop_flag = RLModule([r1_scores, r2_scores, r3_scores],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   self.relation_score_log, labels, self.thresholds,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   self.batch_num, self.step_size)\n",
        "\t\t\tself.thresholds = thresholds\n",
        "\t\t\tself.RL = stop_flag\n",
        "\t\t\tself.relation_score_log.append(relation_scores)\n",
        "\t\t\tself.thresholds_log.append(self.thresholds)\n",
        "\n",
        "\t\treturn combined, center_scores\n",
        "\n",
        "\n",
        "class IntraAgg(nn.Module):\n",
        "\n",
        "\tdef __init__(self, features, feat_dim, cuda=False):\n",
        "\t\tsuper(IntraAgg, self).__init__()\n",
        "\n",
        "\t\tself.features = features\n",
        "\t\tself.cuda = cuda\n",
        "\t\tself.feat_dim = feat_dim\n",
        "\n",
        "\tdef forward(self, nodes, to_neighs_list, batch_scores, neigh_scores, sample_list):\n",
        "\n",
        "\t\t# filer neighbors under given relation\n",
        "\t\tsamp_neighs, samp_scores = filter_neighs_ada_threshold(batch_scores, neigh_scores, to_neighs_list, sample_list)\n",
        "\n",
        "\t\t# find the unique nodes among batch nodes and the filtered neighbors\n",
        "\t\tunique_nodes_list = list(set.union(*samp_neighs))\n",
        "\t\tunique_nodes = {n: i for i, n in enumerate(unique_nodes_list)}\n",
        "\n",
        "\t\t# intra-relation aggregation only with sampled neighbors\n",
        "\t\tmask = Variable(torch.zeros(len(samp_neighs), len(unique_nodes)))\n",
        "\t\tcolumn_indices = [unique_nodes[n] for samp_neigh in samp_neighs for n in samp_neigh]\n",
        "\t\trow_indices = [i for i in range(len(samp_neighs)) for _ in range(len(samp_neighs[i]))]\n",
        "\t\tmask[row_indices, column_indices] = 1\n",
        "\t\tif self.cuda:\n",
        "\t\t\tmask = mask.cuda()\n",
        "\t\tnum_neigh = mask.sum(1, keepdim=True)\n",
        "\t\tmask = mask.div(num_neigh)\n",
        "\t\tif self.cuda:\n",
        "\t\t\tembed_matrix = self.features(torch.LongTensor(unique_nodes_list).cuda())\n",
        "\t\telse:\n",
        "\t\t\tembed_matrix = self.features(torch.LongTensor(unique_nodes_list))\n",
        "\t\tto_feats = mask.mm(embed_matrix)\n",
        "\t\tto_feats = F.relu(to_feats)\n",
        "\t\treturn to_feats, samp_scores\n",
        "\n",
        "\n",
        "def RLModule(scores, scores_log, labels, thresholds, batch_num, step_size):\n",
        "\n",
        "\trelation_scores = []\n",
        "\tstop_flag = True\n",
        "\n",
        "\t# only compute the average neighbor distances for positive nodes\n",
        "\tpos_index = (labels == 1).nonzero().tolist()\n",
        "\tpos_index = [i[0] for i in pos_index]\n",
        "\n",
        "\t# compute average neighbor distances for each relation\n",
        "\tfor score in scores:\n",
        "\t\tpos_scores = itemgetter(*pos_index)(score)\n",
        "\t\tneigh_count = sum([1 if isinstance(i, float) else len(i) for i in pos_scores])\n",
        "\t\tpos_sum = [i if isinstance(i, float) else sum(i) for i in pos_scores]\n",
        "\t\trelation_scores.append(sum(pos_sum) / neigh_count)\n",
        "\n",
        "\tif len(scores_log) % batch_num != 0 or len(scores_log) < 2 * batch_num:\n",
        "\t\t# do not call RL module within the epoch or within the first two epochs\n",
        "\t\trewards = [0, 0, 0]\n",
        "\t\tnew_thresholds = thresholds\n",
        "\telse:\n",
        "\t\t# update thresholds according to average scores in last epoch\n",
        "\t\t# Eq.(5) in the paper\n",
        "\t\tprevious_epoch_scores = [sum(s) / batch_num for s in zip(*scores_log[-2 * batch_num:-batch_num])]\n",
        "\t\tcurrent_epoch_scores = [sum(s) / batch_num for s in zip(*scores_log[-batch_num:])]\n",
        "\n",
        "\t\t# compute reward for each relation and update the thresholds according to reward\n",
        "\t\t# Eq. (6) in the paper\n",
        "\t\trewards = [1 if previous_epoch_scores[i] - s >= 0 else -1 for i, s in enumerate(current_epoch_scores)]\n",
        "\t\tnew_thresholds = [thresholds[i] + step_size if r == 1 else thresholds[i] - step_size for i, r in enumerate(rewards)]\n",
        "\n",
        "\t\t# avoid overflow\n",
        "\t\tnew_thresholds = [0.999 if i > 1 else i for i in new_thresholds]\n",
        "\t\tnew_thresholds = [0.001 if i < 0 else i for i in new_thresholds]\n",
        "\n",
        "\t\tprint(f'epoch scores: {current_epoch_scores}')\n",
        "\t\tprint(f'rewards: {rewards}')\n",
        "\t\tprint(f'thresholds: {new_thresholds}')\n",
        "\n",
        "\t# TODO: add terminal condition\n",
        "\n",
        "\treturn relation_scores, rewards, new_thresholds, stop_flag\n",
        "\n",
        "\n",
        "def filter_neighs_ada_threshold(center_scores, neigh_scores, neighs_list, sample_list):\n",
        "\n",
        "\tsamp_neighs = []\n",
        "\tsamp_scores = []\n",
        "\tfor idx, center_score in enumerate(center_scores):\n",
        "\t\tcenter_score = center_scores[idx][0]\n",
        "\t\tneigh_score = neigh_scores[idx][:, 0].view(-1, 1)\n",
        "\t\tcenter_score = center_score.repeat(neigh_score.size()[0], 1)\n",
        "\t\tneighs_indices = neighs_list[idx]\n",
        "\t\tnum_sample = sample_list[idx]\n",
        "\n",
        "\t\t# compute the L1-distance of batch nodes and their neighbors\n",
        "\t\t# Eq. (2) in paper\n",
        "\t\tscore_diff = torch.abs(center_score - neigh_score).squeeze()\n",
        "\t\tsorted_scores, sorted_indices = torch.sort(score_diff, dim=0, descending=False)\n",
        "\t\tselected_indices = sorted_indices.tolist()\n",
        "\n",
        "\t\t# top-p sampling according to distance ranking and thresholds\n",
        "\t\t# Section 3.3.1 in paper\n",
        "\t\tif len(neigh_scores[idx]) > num_sample + 1:\n",
        "\t\t\tselected_neighs = [neighs_indices[n] for n in selected_indices[:num_sample]]\n",
        "\t\t\tselected_scores = sorted_scores.tolist()[:num_sample]\n",
        "\t\telse:\n",
        "\t\t\tselected_neighs = neighs_indices\n",
        "\t\t\tselected_scores = score_diff.tolist()\n",
        "\t\t\tif isinstance(selected_scores, float):\n",
        "\t\t\t\tselected_scores = [selected_scores]\n",
        "\n",
        "\t\tsamp_neighs.append(set(selected_neighs))\n",
        "\t\tsamp_scores.append(selected_scores)\n",
        "\n",
        "\treturn samp_neighs, samp_scores\n",
        "\n",
        "\n",
        "def mean_inter_agg(num_relations, self_feats, neigh_feats, embed_dim, weight, n, cuda):\n",
        "\n",
        "\t# transform batch node embedding and neighbor embedding in each relation with weight parameter\n",
        "\tcenter_h = torch.mm(self_feats, weight)\n",
        "\tneigh_h = torch.mm(neigh_feats, weight)\n",
        "\n",
        "\t# initialize the final neighbor embedding\n",
        "\tif cuda:\n",
        "\t\taggregated = torch.zeros(size=(n, embed_dim)).cuda()\n",
        "\telse:\n",
        "\t\taggregated = torch.zeros(size=(n, embed_dim))\n",
        "\n",
        "\t# sum neighbor embeddings together\n",
        "\tfor r in range(num_relations):\n",
        "\t\taggregated += neigh_h[r * n:(r + 1) * n, :]\n",
        "\n",
        "\t# sum aggregated neighbor embedding and batch node embedding\n",
        "\t# take the average of embedding and feed them to activation function\n",
        "\tcombined = F.relu((center_h + aggregated) / 4.0)\n",
        "\n",
        "\treturn combined\n",
        "\n",
        "\n",
        "def weight_inter_agg(num_relations, self_feats, neigh_feats, embed_dim, weight, alpha, n, cuda):\n",
        "\n",
        "\t# transform batch node embedding and neighbor embedding in each relation with weight parameter\n",
        "\tcenter_h = torch.mm(self_feats, weight)\n",
        "\tneigh_h = torch.mm(neigh_feats, weight)\n",
        "\n",
        "\t# compute relation weights using softmax\n",
        "\tw = F.softmax(alpha, dim=1)\n",
        "\n",
        "\t# initialize the final neighbor embedding\n",
        "\tif cuda:\n",
        "\t\taggregated = torch.zeros(size=(n, embed_dim)).cuda()\n",
        "\telse:\n",
        "\t\taggregated = torch.zeros(size=(n, embed_dim))\n",
        "\n",
        "\t# add weighted neighbor embeddings in each relation together\n",
        "\tfor r in range(num_relations):\n",
        "\t\taggregated += neigh_h[r * n:(r + 1) * n, :] * w[:, r]\n",
        "\n",
        "\t# sum aggregated neighbor embedding and batch node embedding\n",
        "\t# feed them to activation function\n",
        "\tcombined = nn.relu(center_h + aggregated)\n",
        "\n",
        "\treturn combined\n",
        "\n",
        "\n",
        "def att_inter_agg(num_relations, att_layer, self_feats, neigh_feats, embed_dim, weight, a, n, dropout, training, cuda):\n",
        "\n",
        "\t# transform batch node embedding and neighbor embedding in each relation with weight parameter\n",
        "\tcenter_h = torch.mm(self_feats, weight)\n",
        "\tneigh_h = torch.mm(neigh_feats, weight)\n",
        "\n",
        "\timport pdb\n",
        "\tpdb.set_trace()\n",
        "\t# compute attention weights\n",
        "\tcombined = torch.cat((center_h.repeat(3, 1), neigh_h), dim=1)\n",
        "\te = att_layer(combined.mm(a))\n",
        "\tattention = torch.cat((e[0:n, :], e[n:2 * n, :], e[2 * n:3 * n, :]), dim=1)\n",
        "\tori_attention = F.softmax(attention, dim=1)\n",
        "\tattention = F.dropout(ori_attention, dropout, training=training)\n",
        "\n",
        "\t# initialize the final neighbor embedding\n",
        "\tif cuda:\n",
        "\t\taggregated = torch.zeros(size=(n, embed_dim)).cuda()\n",
        "\telse:\n",
        "\t\taggregated = torch.zeros(size=(n, embed_dim))\n",
        "\n",
        "\t# add neighbor embeddings in each relation together with attention weights\n",
        "\tfor r in range(num_relations):\n",
        "\t\taggregated += torch.mul(attention[:, r].unsqueeze(1).repeat(1, embed_dim), neigh_h[r * n:(r + 1) * n, :])\n",
        "\n",
        "\t# sum aggregated neighbor embedding and batch node embedding\n",
        "\t# feed them to activation function\n",
        "\tcombined = nn.relu((center_h + aggregated))\n",
        "\n",
        "\t# extract the attention weights\n",
        "\tatt = F.softmax(torch.sum(ori_attention, dim=0), dim=0)\n",
        "\n",
        "\treturn combined, att\n",
        "\n",
        "\n",
        "def threshold_inter_agg(num_relations, self_feats, neigh_feats, embed_dim, weight, threshold, n, cuda):\n",
        "\n",
        "\t# transform batch node embedding and neighbor embedding in each relation with weight parameter\n",
        "\tcenter_h = torch.mm(self_feats, weight)\n",
        "\tneigh_h = torch.mm(neigh_feats, weight)\n",
        "\n",
        "\t# initialize the final neighbor embedding\n",
        "\tif cuda:\n",
        "\t\taggregated = torch.zeros(size=(n, embed_dim)).cuda()\n",
        "\telse:\n",
        "\t\taggregated = torch.zeros(size=(n, embed_dim))\n",
        "\n",
        "\t# add weighted neighbor embeddings in each relation together\n",
        "\tfor r in range(num_relations):\n",
        "\t\taggregated += neigh_h[r * n:(r + 1) * n, :] * threshold[r]\n",
        "\n",
        "\t# sum aggregated neighbor embedding and batch node embedding\n",
        "\t# feed them to activation function\n",
        "\tcombined = F.relu(center_h + aggregated)\n",
        "\n",
        "\treturn combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaXBy6bwPIOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c77caeda-da2b-47d6-b275-2139578d26aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute two metrics\n",
            "feature_simi: [0.9905982527769122, 0.9879541091332517, 0.9878335774439747, 0.9878477617186091]\n",
            "label_simi: [0.9089026915113871, 0.17636951567291514, 0.18574074326971865, 0.18376222591604388]\n"
          ]
        }
      ],
      "source": [
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "# Simi_comp\n",
        "\n",
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1)) + 0.01\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "# load data\n",
        "data_name = '/content/drive/MyDrive/DOAN/YelpChi.mat'  # 'Amazon.mat' or 'YelpChi.mat'\n",
        "mode = 'pos'  # if set to pos, it only compute two metrics for positive nodes\n",
        "\n",
        "data = loadmat(data_name)\n",
        "\n",
        "net_list = [data['net_rur'].nonzero(), data['net_rtr'].nonzero(),\n",
        "                 data['net_rsr'].nonzero(), data['homo'].nonzero()]\n",
        "\n",
        "feature = normalize(data['features']).toarray()\n",
        "label = data['label'][0]\n",
        "\n",
        "# extract the edges of positive nodes in each relation graph\n",
        "pos_nodes = set(label.nonzero()[0].tolist())\n",
        "node_list = [set(net[0].tolist()) for net in net_list]\n",
        "pos_node_list = [list(net_nodes.intersection(pos_nodes)) for net_nodes in node_list]\n",
        "pos_idx_list = []\n",
        "for net, pos_node in zip(net_list, pos_node_list):\n",
        "    pos_idx_list.append(np.in1d(net[0], np.array(pos_node)).nonzero()[0])\n",
        "\n",
        "\n",
        "feature_simi_list = []\n",
        "label_simi_list = []\n",
        "print('compute two metrics')\n",
        "for net, pos_idx in zip(net_list, pos_idx_list):\n",
        "    feature_simi = 0\n",
        "    label_simi = 0\n",
        "    if mode == 'pos':  # compute two metrics for positive nodes\n",
        "        for idx in pos_idx:\n",
        "            u, v = net[0][idx], net[1][idx]\n",
        "            feature_simi += np.exp(-1 * np.square(np.linalg.norm(feature[u] - feature[v])))\n",
        "            label_simi += label[u] == label[v]\n",
        "\n",
        "        feature_simi = feature_simi / pos_idx.size\n",
        "        label_simi = label_simi / pos_idx.size\n",
        "\n",
        "    else:  # compute two metrics for all nodes\n",
        "        for u, v in zip(net[0].tolist(), net[1].tolist()):\n",
        "            feature_simi += np.exp(-1 * np.square(np.linalg.norm(feature[u] - feature[v])))\n",
        "            label_simi += label[u] == label[v]\n",
        "\n",
        "        feature_simi = feature_simi / net[0].size\n",
        "        label_simi = label_simi / net[0].size\n",
        "\n",
        "    feature_simi_list.append(feature_simi)\n",
        "    label_simi_list.append(label_simi)\n",
        "\n",
        "print(f'feature_simi: {feature_simi_list}')\n",
        "print(f'label_simi: {label_simi_list}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoIIV972T-ly"
      },
      "source": [
        "## 4. GraphSage model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKNGm3ooUDPv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import random\n",
        "\n",
        "class GraphSage(nn.Module):\n",
        "\t\"\"\"\n",
        "\tVanilla GraphSAGE Model\n",
        "\tCode partially from https://github.com/williamleif/graphsage-simple/\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, num_classes, enc):\n",
        "\t\tsuper(GraphSage, self).__init__()\n",
        "\t\tself.enc = enc\n",
        "\t\tself.xent = nn.CrossEntropyLoss()\n",
        "\t\tself.weight = nn.Parameter(torch.FloatTensor(num_classes, enc.embed_dim))\n",
        "\t\tinit.xavier_uniform_(self.weight)\n",
        "\n",
        "\tdef forward(self, nodes):\n",
        "\t\tembeds = self.enc(nodes)\n",
        "\t\tscores = self.weight.mm(embeds)\n",
        "\t\treturn scores.t()\n",
        "\n",
        "\tdef to_prob(self, nodes):\n",
        "\t\tpos_scores = torch.sigmoid(self.forward(nodes))\n",
        "\t\treturn pos_scores\n",
        "\n",
        "\tdef loss(self, nodes, labels):\n",
        "\t\tscores = self.forward(nodes)\n",
        "\t\treturn self.xent(scores, labels.squeeze())\n",
        "\n",
        "\n",
        "class MeanAggregator(nn.Module):\n",
        "\n",
        "\tdef __init__(self, features, gcn=False):\n",
        "\n",
        "\t\tsuper(MeanAggregator, self).__init__()\n",
        "\n",
        "\t\tself.features = features\n",
        "\t\tself.gcn = gcn\n",
        "\n",
        "\tdef forward(self, nodes, to_neighs, num_sample=10):\n",
        "\t\t# Local pointers to functions (speed hack)\n",
        "\t\t_set = set\n",
        "\t\tif not num_sample is None:\n",
        "\t\t\t_sample = random.sample\n",
        "\t\t\tsamp_neighs = [_set(_sample(to_neigh,\n",
        "\t\t\t\t\t\t\t\t\t\tnum_sample,\n",
        "\t\t\t\t\t\t\t\t\t\t)) if len(to_neigh) >= num_sample else to_neigh for to_neigh in to_neighs]\n",
        "\t\telse:\n",
        "\t\t\tsamp_neighs = to_neighs\n",
        "\n",
        "\t\tif self.gcn:\n",
        "\t\t\tsamp_neighs = [samp_neigh.union(set([int(nodes[i])])) for i, samp_neigh in enumerate(samp_neighs)]\n",
        "\t\tunique_nodes_list = list(set.union(*samp_neighs))\n",
        "\t\tunique_nodes = {n: i for i, n in enumerate(unique_nodes_list)}\n",
        "\t\tmask = Variable(torch.zeros(len(samp_neighs), len(unique_nodes)))\n",
        "\t\tcolumn_indices = [unique_nodes[n] for samp_neigh in samp_neighs for n in samp_neigh]\n",
        "\t\trow_indices = [i for i in range(len(samp_neighs)) for j in range(len(samp_neighs[i]))]\n",
        "\t\tmask[row_indices, column_indices] = 1\n",
        "\t\tmask = mask.to(device)\n",
        "\t\tnum_neigh = mask.sum(1, keepdim=True)\n",
        "\t\tmask = mask.div(num_neigh)\n",
        "\t\tembed_matrix = self.features(torch.LongTensor(unique_nodes_list).to(device))\n",
        "\t\tto_feats = mask.mm(embed_matrix)\n",
        "\t\treturn to_feats\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "\tdef __init__(self, features, feature_dim, embed_dim, adj_lists, aggregator, num_sample=10,\n",
        "\t\t\t\t base_model=None, gcn=False, cuda=False,\n",
        "\t\t\t\t feature_transform=False):\n",
        "\t\tsuper(Encoder, self).__init__()\n",
        "\n",
        "\t\tself.features = features\n",
        "\t\tself.feat_dim = feature_dim\n",
        "\t\tself.adj_lists = adj_lists\n",
        "\t\tself.aggregator = aggregator\n",
        "\t\tself.num_sample = num_sample\n",
        "\t\tif base_model != None:\n",
        "\t\t\tself.base_model = base_model\n",
        "\n",
        "\t\tself.gcn = gcn\n",
        "\t\tself.embed_dim = embed_dim\n",
        "\t\tself.cuda = cuda\n",
        "\t\tself.aggregator.cuda = cuda\n",
        "\t\tself.weight = nn.Parameter(\n",
        "\t\t\ttorch.FloatTensor(embed_dim, self.feat_dim if self.gcn else 2 * self.feat_dim))\n",
        "\t\tinit.xavier_uniform_(self.weight)\n",
        "\n",
        "\tdef forward(self, nodes):\n",
        "\t\t\"\"\"\n",
        "\t\tGenerates embeddings for a batch of nodes.\n",
        "\n",
        "\t\tnodes     -- list of nodes\n",
        "\t\t\"\"\"\n",
        "\t\tneigh_feats = self.aggregator.forward(nodes, [self.adj_lists[int(node)] for node in nodes],\n",
        "\t\t\t\t\t\t\t\t\t\t\t  self.num_sample)\n",
        "\n",
        "\t\tif isinstance(nodes, list):\n",
        "\t\t\tindex = torch.LongTensor(nodes).cuda()\n",
        "\t\telse:\n",
        "\t\t\tindex = nodes\n",
        "\n",
        "\t\tif not self.gcn:\n",
        "\t\t\tif self.cuda:\n",
        "\t\t\t\tself_feats = self.features(index)\n",
        "\t\t\telse:\n",
        "\t\t\t\tself_feats = self.features(index)\n",
        "\t\t\tcombined = torch.cat((self_feats, neigh_feats), dim=1)\n",
        "\t\telse:\n",
        "\t\t\tcombined = neigh_feats\n",
        "\t\tcombined = F.relu(self.weight.mm(combined.t()))\n",
        "\t\treturn combined"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD-2a9PnRu9Y"
      },
      "source": [
        "## 5. Test Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rulRd8-YL5DR"
      },
      "outputs": [],
      "source": [
        "def test_care(test_cases, labels, model, batch_size):\n",
        "\n",
        "\ttest_batch_num = int(len(test_cases) / batch_size) + 1\n",
        "\tf1_gnn = 0.0\n",
        "\tacc_gnn = 0.0\n",
        "\trecall_gnn = 0.0\n",
        "\tf1_label1 = 0.0\n",
        "\tacc_label1 = 0.00\n",
        "\trecall_label1 = 0.0\n",
        "\tgnn_list = []\n",
        "\tlabel_list1 = []\n",
        "\n",
        "\tfor iteration in range(test_batch_num):\n",
        "\t\ti_start = iteration * batch_size\n",
        "\t\ti_end = min((iteration + 1) * batch_size, len(test_cases))\n",
        "\t\tbatch_nodes = test_cases[i_start:i_end]\n",
        "\t\tbatch_label = labels[i_start:i_end]\n",
        "\t\tgnn_prob, label_prob1 = model.to_prob(batch_nodes, batch_label, train_flag=False)\n",
        "\n",
        "\t\tf1_gnn += f1_score(batch_label, gnn_prob.data.cpu().numpy().argmax(axis=1), average=\"macro\")\n",
        "\t\tacc_gnn += accuracy_score(batch_label, gnn_prob.data.cpu().numpy().argmax(axis=1))\n",
        "\t\trecall_gnn += recall_score(batch_label, gnn_prob.data.cpu().numpy().argmax(axis=1), average=\"macro\")\n",
        "\n",
        "\t\tf1_label1 += f1_score(batch_label, label_prob1.data.cpu().numpy().argmax(axis=1), average=\"macro\")\n",
        "\t\tacc_label1 += accuracy_score(batch_label, label_prob1.data.cpu().numpy().argmax(axis=1))\n",
        "\t\trecall_label1 += recall_score(batch_label, label_prob1.data.cpu().numpy().argmax(axis=1), average=\"macro\")\n",
        "\n",
        "\t\tgnn_list.extend(gnn_prob.data.cpu().numpy()[:, 1].tolist())\n",
        "\t\tlabel_list1.extend(label_prob1.data.cpu().numpy()[:, 1].tolist())\n",
        "\n",
        "\tauc_gnn = roc_auc_score(labels, np.array(gnn_list))\n",
        "\tap_gnn = average_precision_score(labels, np.array(gnn_list))\n",
        "\tauc_label1 = roc_auc_score(labels, np.array(label_list1))\n",
        "\tap_label1 = average_precision_score(labels, np.array(label_list1))\n",
        "\tprint(f\"GNN F1: {f1_gnn / test_batch_num:.4f}\")\n",
        "\tprint(f\"GNN Accuracy: {acc_gnn / test_batch_num:.4f}\")\n",
        "\tprint(f\"GNN Recall: {recall_gnn / test_batch_num:.4f}\")\n",
        "\tprint(f\"GNN auc: {auc_gnn:.4f}\")\n",
        "\tprint(f\"GNN ap: {ap_gnn:.4f}\")\n",
        "\n",
        "\treturn auc_gnn, auc_label1, recall_gnn, recall_label1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_sage(test_cases, labels, model, batch_size):\n",
        "\ttest_batch_num = int(len(test_cases) / batch_size) + 1\n",
        "\tf1_gnn = 0.0\n",
        "\tacc_gnn = 0.0\n",
        "\trecall_gnn = 0.0\n",
        "\tgnn_list = []\n",
        "\tfor iteration in range(test_batch_num):\n",
        "\t\ti_start = iteration * batch_size\n",
        "\t\ti_end = min((iteration + 1) * batch_size, len(test_cases))\n",
        "\t\tbatch_nodes = test_cases[i_start:i_end]\n",
        "\t\tbatch_label = labels[i_start:i_end]\n",
        "\t\tgnn_prob = model.to_prob(batch_nodes)\n",
        "\t\tf1_gnn += f1_score(batch_label, gnn_prob.data.cpu().numpy().argmax(axis=1), average=\"macro\")\n",
        "\t\tacc_gnn += accuracy_score(batch_label, gnn_prob.data.cpu().numpy().argmax(axis=1))\n",
        "\t\trecall_gnn += recall_score(batch_label, gnn_prob.data.cpu().numpy().argmax(axis=1), average=\"macro\")\n",
        "\t\tgnn_list.extend(gnn_prob.data.cpu().numpy()[:, 1].tolist())\n",
        "\n",
        "\tauc_gnn = roc_auc_score(labels, np.array(gnn_list))\n",
        "\tap_gnn = average_precision_score(labels, np.array(gnn_list))\n",
        "\tprint(f\"GNN F1: {f1_gnn / test_batch_num:.4f}\")\n",
        "\tprint(f\"GNN Accuracy: {acc_gnn / test_batch_num:.4f}\")\n",
        "\tprint(f\"GNN Recall: {recall_gnn / test_batch_num:.4f}\")\n",
        "\tprint(f\"GNN auc: {auc_gnn:.4f}\")\n",
        "\tprint(f\"GNN ap: {ap_gnn:.4f}\")"
      ],
      "metadata": {
        "id": "0QocFN-gwGgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8XA3cgnTI58"
      },
      "source": [
        "## 6. Train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 Splitting Dataset"
      ],
      "metadata": {
        "id": "oAW59VmQiqhY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VBf_aynPQBH"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# load graph, feature, and label\n",
        "[homo, relation1, relation2, relation3], feat_data, labels = load_data(\"YelpChi\")\n",
        "\n",
        "# train_test split\n",
        "index = list(range(len(labels)))\n",
        "idx_train, idx_test, y_train, y_test = train_test_split(index, labels, stratify=labels, test_size=0.20,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\trandom_state=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"homo: {homo[0]}\")\n",
        "print(f\"relation 1: {relation1[0]}\")\n",
        "print(f\"relation2: {relation2[0]}\")\n",
        "print(f\"relation3: {relation3[0]}\")\n",
        "print(f\"feat_data: {feat_data[0]}\")\n",
        "print(f\"label : {labels[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvyKT_t4ouUJ",
        "outputId": "de58949b-55bb-46c4-99be-7b50a93af5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "homo: {0, 2, 6702}\n",
            "relation 1: {0}\n",
            "relation2: {0}\n",
            "relation3: {0, 2, 6702}\n",
            "feat_data: [0.02237555 0.07049484 0.42868165 0.99998516 0.99998516 0.39845686\n",
            " 0.82359225 0.497025   0.96545738 0.15026337 0.99998516 0.58321834\n",
            " 0.58391572 0.38148231 0.38164552 0.99997373 0.64309172 0.99997373\n",
            " 0.80251163 0.78335917 0.75516906 0.77051205 0.9480598  0.86777185\n",
            " 0.99502488 0.91044776 0.07960199 0.00995025 0.01492537 0.5920398\n",
            " 0.13930348 0.49751244]\n",
            "label : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 SageGraph training\n",
        "\n"
      ],
      "metadata": {
        "id": "oxE_rzeIiwHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize model input\n",
        "features = nn.Embedding(feat_data.shape[0], feat_data.shape[1])\n",
        "feat_data = normalize(feat_data)\n",
        "features.weight = nn.Parameter(torch.FloatTensor(feat_data), requires_grad=False)\n",
        "features.to(device)\n",
        "adj_lists = homo\n",
        "\n",
        "agg1 = MeanAggregator(features)\n",
        "\n",
        "enc1 = Encoder(features, feat_data.shape[1], 64, adj_lists, agg1, gcn=True, cuda= True)\n",
        "\n",
        "# the vanilla GraphSAGE model as baseline\n",
        "enc1.num_samples = 5\n",
        "gnn_model = GraphSage(2, enc1)"
      ],
      "metadata": {
        "id": "-csmrduKf4wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split pos neg sets for under-sampling\n",
        "train_pos, train_neg = pos_neg_split(idx_train, y_train)\n",
        "\n",
        "# Initialize model input\n",
        "features = nn.Embedding(feat_data.shape[0], feat_data.shape[1])\n",
        "feat_data = torch.FloatTensor(normalize(feat_data))\n",
        "features.weight = nn.Parameter(feat_data, requires_grad=False)\n",
        "features.to(device)\n",
        "# Set input graph\n",
        "## Run Sage First\n",
        "model = 'SAGE'\n",
        "adj_lists = homo\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "agg1 = MeanAggregator(features)\n",
        "\n",
        "enc1 = Encoder(features, feat_data.shape[1], 64, adj_lists, agg1, gcn=True, cuda=cuda)\n",
        "\n",
        "# The vanilla GraphSAGE model as baseline\n",
        "enc1.num_samples = 5\n",
        "gnn_model = GraphSage(2, enc1)\n",
        "\n",
        "\n",
        "gnn_model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, gnn_model.parameters()), lr=0.01, weight_decay=1e-3)"
      ],
      "metadata": {
        "id": "Mjw_ansHxApn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "times = []\n",
        "performance_log = []\n",
        "epochs = 30\n",
        "batch_size = 1024\n",
        "for epoch in range(epochs):\n",
        "    # Randomly under-sampling negative nodes for each epoch\n",
        "    sampled_idx_train = undersample(train_pos, train_neg, scale=1)\n",
        "    random.shuffle(sampled_idx_train)\n",
        "\n",
        "    # Send number of batches to model to let the RLModule know the training progress\n",
        "    num_batches = int(len(sampled_idx_train) / batch_size) + 1\n",
        "\n",
        "    loss = 0.0\n",
        "    epoch_time = 0\n",
        "\n",
        "    # Mini-batch training\n",
        "    for batch in range(num_batches):\n",
        "        start_time = time.time()\n",
        "        i_start = batch * batch_size\n",
        "        i_end = min((batch + 1) * batch_size, len(sampled_idx_train))\n",
        "\n",
        "        batch_nodes = sampled_idx_train[i_start:i_end]\n",
        "        batch_label = labels[np.array(batch_nodes)]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = gnn_model.loss(batch_nodes, torch.cuda.LongTensor(batch_label))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        end_time = time.time()\n",
        "        epoch_time += end_time - start_time\n",
        "        loss += loss.item()\n",
        "\n",
        "    print(f'Epoch: {epoch}, loss: {loss.item() / num_batches}, time: {epoch_time}s')"
      ],
      "metadata": {
        "id": "eA0KjUkhdBBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8526394a-2aa8-4d6d-9647-623bdb7243d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-0de4f801aa3b>:26: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  loss = gnn_model.loss(batch_nodes, torch.cuda.LongTensor(batch_label))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 0.23152734835942587, time: 0.76222825050354s\n",
            "Epoch: 1, loss: 0.23148196935653687, time: 0.21338462829589844s\n",
            "Epoch: 2, loss: 0.23104302088419595, time: 0.2107713222503662s\n",
            "Epoch: 3, loss: 0.23096140225728354, time: 0.22952032089233398s\n",
            "Epoch: 4, loss: 0.23092949390411377, time: 0.22460293769836426s\n",
            "Epoch: 5, loss: 0.23098824421564737, time: 0.3942244052886963s\n",
            "Epoch: 6, loss: 0.2310264309247335, time: 0.35793375968933105s\n",
            "Epoch: 7, loss: 0.23103690147399902, time: 0.3151240348815918s\n",
            "Epoch: 8, loss: 0.23103843132654825, time: 0.32343196868896484s\n",
            "Epoch: 9, loss: 0.23103390137354532, time: 0.39734387397766113s\n",
            "Epoch: 10, loss: 0.23105684916178384, time: 0.34145450592041016s\n",
            "Epoch: 11, loss: 0.23104788859685263, time: 0.3567466735839844s\n",
            "Epoch: 12, loss: 0.23103861014048258, time: 0.4466519355773926s\n",
            "Epoch: 13, loss: 0.2310813864072164, time: 0.33035945892333984s\n",
            "Epoch: 14, loss: 0.23104757070541382, time: 0.39752960205078125s\n",
            "Epoch: 15, loss: 0.23105047146479288, time: 0.3061971664428711s\n",
            "Epoch: 16, loss: 0.2310520807902018, time: 0.2372279167175293s\n",
            "Epoch: 17, loss: 0.23104838530222574, time: 0.2429511547088623s\n",
            "Epoch: 18, loss: 0.23105148474375406, time: 0.22798705101013184s\n",
            "Epoch: 19, loss: 0.2310481866200765, time: 0.21290135383605957s\n",
            "Epoch: 20, loss: 0.23105070988337198, time: 0.2062373161315918s\n",
            "Epoch: 21, loss: 0.23104923963546753, time: 0.21626996994018555s\n",
            "Epoch: 22, loss: 0.23104894161224365, time: 0.30529356002807617s\n",
            "Epoch: 23, loss: 0.2310490608215332, time: 0.2893350124359131s\n",
            "Epoch: 24, loss: 0.2310490608215332, time: 0.31793999671936035s\n",
            "Epoch: 25, loss: 0.2310490608215332, time: 0.2554662227630615s\n",
            "Epoch: 26, loss: 0.2310490608215332, time: 0.24458074569702148s\n",
            "Epoch: 27, loss: 0.23104908068974814, time: 0.27735114097595215s\n",
            "Epoch: 28, loss: 0.23104908068974814, time: 0.24654889106750488s\n",
            "Epoch: 29, loss: 0.2310490608215332, time: 0.2745051383972168s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(gnn_model.state_dict(), '/content/drive/MyDrive/DOAN/SAGE_model.pth')"
      ],
      "metadata": {
        "id": "KZJNLzHS0jDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_model.load_state_dict(torch.load('/content/drive/MyDrive/DOAN/SAGE_model.pth'))"
      ],
      "metadata": {
        "id": "OjOGmIvQwTLb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b52a97d-189f-4d88-e2a1-c27415bffc67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQC0Guz7wS4-",
        "outputId": "e21c75a2-ff5a-4052-db54-9c22b306727a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphSage(\n",
              "  (enc): Encoder(\n",
              "    (features): Embedding(45954, 32)\n",
              "    (aggregator): MeanAggregator(\n",
              "      (features): Embedding(45954, 32)\n",
              "    )\n",
              "  )\n",
              "  (xent): CrossEntropyLoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1024\n",
        "test_sage(idx_test, y_test, gnn_model, batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PslxBGbKyUo8",
        "outputId": "e1a2d221-d840-41c8-db8f-d9e6f9bd57bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GNN F1: 0.4608\n",
            "GNN Accuracy: 0.8547\n",
            "GNN Recall: 0.5000\n",
            "GNN auc: 0.5000\n",
            "GNN ap: 0.1453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 CARE-CNN training"
      ],
      "metadata": {
        "id": "b2o7VU9f-lDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adj_lists = [relation1, relation2, relation3]\n",
        "emb_size = 4\n",
        "inter = 'GNN'\n",
        "step_size = 2e-2\n",
        "lambda_1 = 2\n",
        "lambda_2 = 1e-3\n",
        "lr = 0.01\n",
        "\n",
        "intra1 = IntraAgg(features, feat_data.shape[1], cuda=cuda)\n",
        "intra2 = IntraAgg(features, feat_data.shape[1], cuda=cuda)\n",
        "intra3 = IntraAgg(features, feat_data.shape[1], cuda=cuda)\n",
        "inter1 = InterAgg(features, feat_data.shape[1], emb_size, adj_lists, [intra1, intra2, intra3], inter=inter, step_size = step_size, cuda=cuda)\n",
        "\n",
        "gnn_care_model = OneLayerCARE(2, inter1, lambda_1)\n",
        "\n",
        "gnn_care_model.to(device)\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, gnn_model.parameters()), lr=lr, weight_decay=lambda_2)\n",
        "times = []\n",
        "performance_log = []"
      ],
      "metadata": {
        "id": "HA_U-jXwv3U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "batch_size = 1024\n",
        "for epoch in range(num_epochs):\n",
        "\t# randomly under-sampling negative nodes for each epoch\n",
        "\tsampled_idx_train = undersample(train_pos, train_neg, scale=1)\n",
        "\trd.shuffle(sampled_idx_train)\n",
        "\n",
        "\t# send number of batches to model to let the RLModule know the training progress\n",
        "\tnum_batches = int(len(sampled_idx_train) / batch_size) + 1\n",
        "\tinter1.batch_num = num_batches\n",
        "\n",
        "\tloss = 0.0\n",
        "\tepoch_time = 0\n",
        "\n",
        "\t# mini-batch training\n",
        "\tfor batch in range(num_batches):\n",
        "\t\tstart_time = time.time()\n",
        "\t\ti_start = batch * batch_size\n",
        "\t\ti_end = min((batch + 1) * batch_size, len(sampled_idx_train))\n",
        "\t\tbatch_nodes = sampled_idx_train[i_start:i_end]\n",
        "\t\tbatch_label = labels[np.array(batch_nodes)]\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\t#if cuda:\n",
        "\t\tloss = gnn_care_model.loss(batch_nodes, Variable(torch.cuda.LongTensor(batch_label)))\n",
        "\t\t#else:\n",
        "\t\t#loss = gnn_model.loss(batch_nodes, Variable(torch.LongTensor(batch_label)))\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\tend_time = time.time()\n",
        "\t\tepoch_time += end_time - start_time\n",
        "\t\tloss += loss.item()\n",
        "\n",
        "\tprint(f'Epoch: {epoch}, loss: {loss.item() / num_batches}, time: {epoch_time}s')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9gJ7_lj_A52",
        "outputId": "320adb88-a566-4c89-b9ba-96c731a693cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-6334cbfa56c5>:24: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  loss = gnn_care_model.loss(batch_nodes, Variable(torch.cuda.LongTensor(batch_label)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 0.6957997481028239, time: 12.98915982246399s\n",
            "Epoch: 1, loss: 0.696735143661499, time: 7.274843692779541s\n",
            "epoch scores: [0.0012478944959243992, 0.0038967103581130625, 0.004135368966118057]\n",
            "rewards: [-1, 1, 1]\n",
            "thresholds: [0.48, 0.52, 0.52]\n",
            "Epoch: 2, loss: 0.6932341257731119, time: 6.68493914604187s\n",
            "epoch scores: [0.0013454673554313358, 0.004144397237324971, 0.004321600308726712]\n",
            "rewards: [-1, -1, -1]\n",
            "thresholds: [0.45999999999999996, 0.5, 0.5]\n",
            "Epoch: 3, loss: 0.6954858303070068, time: 7.167391777038574s\n",
            "epoch scores: [0.0012790461918918798, 0.0039909658546776715, 0.0041675485349907905]\n",
            "rewards: [1, 1, 1]\n",
            "thresholds: [0.48, 0.52, 0.52]\n",
            "Epoch: 4, loss: 0.6953803698221842, time: 6.701725959777832s\n",
            "epoch scores: [0.001286624546123115, 0.004069985749555022, 0.0041813805296561585]\n",
            "rewards: [-1, -1, -1]\n",
            "thresholds: [0.45999999999999996, 0.5, 0.5]\n",
            "Epoch: 5, loss: 0.6942814191182455, time: 7.268238306045532s\n",
            "epoch scores: [0.0013151007384623813, 0.004045392464784802, 0.004234779870985707]\n",
            "rewards: [-1, 1, -1]\n",
            "thresholds: [0.43999999999999995, 0.52, 0.48]\n",
            "Epoch: 6, loss: 0.693007230758667, time: 6.715016841888428s\n",
            "epoch scores: [0.0012844244921099022, 0.004179247997386529, 0.004086053034410367]\n",
            "rewards: [1, -1, 1]\n",
            "thresholds: [0.45999999999999996, 0.5, 0.5]\n",
            "Epoch: 7, loss: 0.6979236602783203, time: 7.19032096862793s\n",
            "epoch scores: [0.0012614024528761678, 0.003993870934709273, 0.004174770263493469]\n",
            "rewards: [1, 1, -1]\n",
            "thresholds: [0.48, 0.52, 0.48]\n",
            "Epoch: 8, loss: 0.6943173408508301, time: 6.665755987167358s\n",
            "epoch scores: [0.0013174013714121644, 0.004116891836718176, 0.004005337546788535]\n",
            "rewards: [-1, -1, 1]\n",
            "thresholds: [0.45999999999999996, 0.5, 0.5]\n",
            "Epoch: 9, loss: 0.6899778842926025, time: 7.263198614120483s\n",
            "epoch scores: [0.001239724328752082, 0.003950678815061817, 0.004069329073747196]\n",
            "rewards: [1, 1, -1]\n",
            "thresholds: [0.48, 0.52, 0.48]\n",
            "Epoch: 10, loss: 0.6938530604044596, time: 6.798154592514038s\n",
            "epoch scores: [0.0012219902735728404, 0.00418470683990835, 0.004065892081689796]\n",
            "rewards: [1, -1, 1]\n",
            "thresholds: [0.5, 0.5, 0.5]\n",
            "Epoch: 11, loss: 0.69273575146993, time: 7.067193508148193s\n",
            "epoch scores: [0.0013028682318186808, 0.00402941162826311, 0.004137260726144441]\n",
            "rewards: [-1, 1, -1]\n",
            "thresholds: [0.48, 0.52, 0.48]\n",
            "Epoch: 12, loss: 0.6940857569376627, time: 7.076374530792236s\n",
            "epoch scores: [0.0012937457913227252, 0.0041660553470253625, 0.004096995526658011]\n",
            "rewards: [1, -1, 1]\n",
            "thresholds: [0.5, 0.5, 0.5]\n",
            "Epoch: 13, loss: 0.6940668423970541, time: 6.915499210357666s\n",
            "epoch scores: [0.0012901794218156222, 0.0040202854493298626, 0.004170220193909678]\n",
            "rewards: [1, 1, -1]\n",
            "thresholds: [0.52, 0.52, 0.48]\n",
            "Epoch: 14, loss: 0.6930548350016276, time: 7.379802227020264s\n",
            "epoch scores: [0.001395356431562578, 0.004101921572802222, 0.004026859486867193]\n",
            "rewards: [-1, -1, 1]\n",
            "thresholds: [0.5, 0.5, 0.5]\n",
            "Epoch: 15, loss: 0.6940937042236328, time: 6.596045017242432s\n",
            "epoch scores: [0.001257212040482491, 0.004051529930170101, 0.004185547766186587]\n",
            "rewards: [1, 1, -1]\n",
            "thresholds: [0.52, 0.52, 0.48]\n",
            "Epoch: 16, loss: 0.6952238082885742, time: 7.73190712928772s\n",
            "epoch scores: [0.0013492876372831473, 0.004141305345849788, 0.004007494825335234]\n",
            "rewards: [-1, -1, 1]\n",
            "thresholds: [0.5, 0.5, 0.5]\n",
            "Epoch: 17, loss: 0.6981374422709147, time: 6.198704719543457s\n",
            "epoch scores: [0.0012494837755646028, 0.004011632544167758, 0.004158401096655519]\n",
            "rewards: [1, 1, -1]\n",
            "thresholds: [0.52, 0.52, 0.48]\n",
            "Epoch: 18, loss: 0.6931776205698649, time: 7.691974878311157s\n",
            "epoch scores: [0.0013785410596457175, 0.004093762696384514, 0.003977501342119782]\n",
            "rewards: [-1, -1, 1]\n",
            "thresholds: [0.5, 0.5, 0.5]\n",
            "Epoch: 19, loss: 0.6952764193216959, time: 7.310048580169678s\n",
            "epoch scores: [0.0012914938050854238, 0.004006627921076821, 0.004140998371612975]\n",
            "rewards: [1, 1, -1]\n",
            "thresholds: [0.52, 0.52, 0.48]\n",
            "Epoch: 20, loss: 0.6937352021535238, time: 7.7708117961883545s\n",
            "epoch scores: [0.0014218216859843364, 0.004180269575164362, 0.004062202843820588]\n",
            "rewards: [-1, -1, 1]\n",
            "thresholds: [0.5, 0.5, 0.5]\n",
            "Epoch: 21, loss: 0.6919662157694498, time: 6.192398548126221s\n",
            "epoch scores: [0.001309031165598832, 0.004016879096251691, 0.004143278428617472]\n",
            "rewards: [1, 1, -1]\n",
            "thresholds: [0.52, 0.52, 0.48]\n",
            "Epoch: 22, loss: 0.6935234864552816, time: 7.63162899017334s\n",
            "epoch scores: [0.001394273370006558, 0.004166971214330809, 0.004021827708808139]\n",
            "rewards: [-1, -1, 1]\n",
            "thresholds: [0.5, 0.5, 0.5]\n",
            "Epoch: 23, loss: 0.6933931509653727, time: 6.206817865371704s\n",
            "epoch scores: [0.0012850841227450183, 0.004002762673316789, 0.004167851742519209]\n",
            "rewards: [1, 1, -1]\n",
            "thresholds: [0.52, 0.52, 0.48]\n",
            "Epoch: 24, loss: 0.6986611684163412, time: 7.70685601234436s\n",
            "epoch scores: [0.001392984557911171, 0.004176929828274694, 0.004039814879328375]\n",
            "rewards: [-1, -1, 1]\n",
            "thresholds: [0.5, 0.5, 0.5]\n",
            "Epoch: 25, loss: 0.6939821243286133, time: 6.065792560577393s\n",
            "epoch scores: [0.001289626764472223, 0.003939320609690345, 0.00407556635658659]\n",
            "rewards: [1, 1, -1]\n",
            "thresholds: [0.52, 0.52, 0.48]\n",
            "Epoch: 26, loss: 0.6958381334940592, time: 7.709370136260986s\n",
            "epoch scores: [0.0013393735808619248, 0.004113856820483569, 0.003986352957863308]\n",
            "rewards: [-1, -1, 1]\n",
            "thresholds: [0.5, 0.5, 0.5]\n",
            "Epoch: 27, loss: 0.6936202049255371, time: 6.300232172012329s\n",
            "epoch scores: [0.0012950358207693554, 0.003944024487938356, 0.0040601696024558445]\n",
            "rewards: [1, 1, -1]\n",
            "thresholds: [0.52, 0.52, 0.48]\n",
            "Epoch: 28, loss: 0.6963156859079996, time: 7.468440294265747s\n",
            "epoch scores: [0.0014805810390851784, 0.0041364197003464385, 0.004060061555750779]\n",
            "rewards: [-1, -1, 1]\n",
            "thresholds: [0.5, 0.5, 0.5]\n",
            "Epoch: 29, loss: 0.6953113079071045, time: 6.573467493057251s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(gnn_care_model.state_dict(), '/content/drive/MyDrive/DOAN/CARE_model2.pth')"
      ],
      "metadata": {
        "id": "zQH7Ec3bAOwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_care_model.load_state_dict(torch.load('/content/drive/MyDrive/DOAN/CARE_model2.pth'))"
      ],
      "metadata": {
        "id": "37tGRos_BgR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20454615-92d5-4d72-caf5-736333b8fad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance_log = []\n",
        "batch_size = 1024\n",
        "gnn_auc, label_auc, gnn_recall, label_recall = test_care(idx_test, y_test, gnn_care_model, batch_size)\n",
        "performance_log.append([gnn_auc, label_auc, gnn_recall, label_recall])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyjUrCWL8F1r",
        "outputId": "62e9d40e-7d40-42da-9b35-e98f107d0519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GNN F1: 0.5980\n",
            "GNN Accuracy: 0.6942\n",
            "GNN Recall: 0.7000\n",
            "GNN auc: 0.7665\n",
            "GNN ap: 0.3810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 SPARK"
      ],
      "metadata": {
        "id": "zchplFVQDgiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHGsOoZ780xb",
        "outputId": "b99b2cc5-3639-4111-c61a-d376f43e2b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=a8a5e209f8eda1ac1f2e4b7e8c431099dafd66612d7f1992987f12ad8d5f9595\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.conf import SparkConf\n",
        "\n",
        "spark = SparkSession \\\n",
        ".builder \\\n",
        ".appName(\"spark-dl-inference\") \\\n",
        ".master(\"local[*]\") \\\n",
        ".config(\"spark.executor.memory\", \"8g\") \\\n",
        ".config(\"spark.driver.memory\", \"8g\") \\\n",
        ".config(\"spark.python.worker.reuse\",True) \\\n",
        ".getOrCreate()\n",
        "# Create a SparkConf object\n",
        "conf=SparkConf()\n",
        "\n",
        "print(\"spark.executor.memory = \", conf.get(\"spark.executor.memory\"))\n",
        "print(\"spark.driver.memory = \", conf.get(\"spark.driver.memory\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1F6FN-4oRWN",
        "outputId": "a855ffcb-82e6-4a3c-ea7c-3039a502f2f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark.executor.memory =  8g\n",
            "spark.driver.memory =  8g\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from pyspark.ml.functions import predict_batch_udf\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.functions import array, col, struct, pandas_udf\n",
        "from pyspark.sql.types import ArrayType, FloatType, Union, Dict, IntegerType\n",
        "from pyspark.sql.functions import col, floor, collect_list, monotonically_increasing_id\n",
        "from pyspark.sql.functions import explode, posexplode, udf\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "gSoD1kzEq455"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_input = pd.read_csv('/content/drive/MyDrive/DOAN/test_a.csv')"
      ],
      "metadata": {
        "id": "TPm3awvWLZ4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_input.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "32Ga9Et0MkxL",
        "outputId": "6240036d-d3cd-4cff-f48d-66e27dcd47ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   nodes  label\n",
              "0  35042      0\n",
              "1  27485      0\n",
              "2  16164      0\n",
              "3  21204      0\n",
              "4  12201      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26894514-3865-46a4-9e22-72bd419c749b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nodes</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35042</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27485</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16164</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21204</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12201</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26894514-3865-46a4-9e22-72bd419c749b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-26894514-3865-46a4-9e22-72bd419c749b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-26894514-3865-46a4-9e22-72bd419c749b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-151be11d-655b-4a1a-998a-7190f9b9ce9a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-151be11d-655b-4a1a-998a-7190f9b9ce9a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-151be11d-655b-4a1a-998a-7190f9b9ce9a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "val_input",
              "summary": "{\n  \"name\": \"val_input\",\n  \"rows\": 27573,\n  \"fields\": [\n    {\n      \"column\": \"nodes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13244,\n        \"min\": 3,\n        \"max\": 45952,\n        \"num_unique_values\": 27573,\n        \"samples\": [\n          16268,\n          3332,\n          11160\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df = spark.createDataFrame(val_input.drop('label', axis = 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g-ain1rLfb9",
        "outputId": "d8567f27-4c97-4e7f-a149-afea913c2cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 330 ms, sys: 1.8 ms, total: 332 ms\n",
            "Wall time: 361 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4YJuHCNf5J4",
        "outputId": "e9e42377-9621-4b92-e478-db4b50b7a219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|nodes|\n",
            "+-----+\n",
            "|35042|\n",
            "|27485|\n",
            "|16164|\n",
            "|21204|\n",
            "|12201|\n",
            "|38716|\n",
            "|18519|\n",
            "| 8865|\n",
            "| 3804|\n",
            "| 7383|\n",
            "|41976|\n",
            "| 1413|\n",
            "|16995|\n",
            "|20697|\n",
            "|42494|\n",
            "|41349|\n",
            "| 8917|\n",
            "|29393|\n",
            "|12982|\n",
            "| 2639|\n",
            "+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"group_id\", floor(monotonically_increasing_id() / 5))\n",
        "grouped_df = df.groupBy(\"group_id\").agg(collect_list(\"nodes\").alias(\"data_grouped\"))\n",
        "grouped_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-MAYQGyPcpY",
        "outputId": "2591a1e1-294f-4d27-ab4c-a832b17ffe53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------------------------------+\n",
            "|group_id|data_grouped                       |\n",
            "+--------+-----------------------------------+\n",
            "|0       |[35042, 27485, 16164, 21204, 12201]|\n",
            "|1       |[38716, 18519, 8865, 3804, 7383]   |\n",
            "|2       |[41976, 1413, 16995, 20697, 42494] |\n",
            "|3       |[41349, 8917, 29393, 12982, 2639]  |\n",
            "|4       |[110, 24197, 23445, 9455, 45367]   |\n",
            "|5       |[44530, 42078, 38127, 3992, 28694] |\n",
            "|6       |[9735, 29484, 17637, 28373, 22435] |\n",
            "|7       |[23158, 8108, 5255, 18665, 2760]   |\n",
            "|8       |[35284, 760, 42136, 32438, 19168]  |\n",
            "|9       |[45690, 24381, 2646, 16977, 19387] |\n",
            "|10      |[34245, 26156, 39503, 22873, 26840]|\n",
            "|11      |[16111, 15357, 35272, 36345, 44553]|\n",
            "|12      |[15606, 29320, 29551, 34946, 41177]|\n",
            "|13      |[16681, 10134, 12877, 22613, 42802]|\n",
            "|14      |[6886, 25433, 24541, 36788, 1891]  |\n",
            "|15      |[23262, 41729, 27314, 34693, 8374] |\n",
            "|16      |[9162, 23462, 14412, 34839, 21668] |\n",
            "|17      |[34966, 37425, 37571, 4551, 45439] |\n",
            "|18      |[35508, 41521, 28227, 29346, 28131]|\n",
            "|19      |[13244, 10167, 24517, 22931, 27083]|\n",
            "+--------+-----------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnCnD_D8RgBN",
        "outputId": "ee6399b5-ce39-4f81-9b49-ced4f8624da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------+\n",
            "|nodes|group_id|\n",
            "+-----+--------+\n",
            "|35042|       0|\n",
            "|27485|       0|\n",
            "|16164|       0|\n",
            "|21204|       0|\n",
            "|12201|       0|\n",
            "+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "grouped_df.write.mode(\"overwrite\").parquet(\"YelpChi_cut5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsLgCWEaJFhG",
        "outputId": "4a8886e1-36dd-4e18-e14a-82911fc63e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 8.71 ms, sys: 1.98 ms, total: 10.7 ms\n",
            "Wall time: 1.19 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Care model"
      ],
      "metadata": {
        "id": "pjQyjG9xNJ01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.functions import predict_batch_udf\n",
        "\n",
        "def predict(inputs) -> np.ndarray:\n",
        "  output,_ = gnn_care_model.to_prob(inputs, [0,0,0,0,0], train_flag=False)\n",
        "  return output.data.cpu().numpy().argmax(axis=1).flatten().tolist()"
      ],
      "metadata": {
        "id": "xqsoKgkxMdH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_udf = udf(predict, ArrayType(IntegerType()))"
      ],
      "metadata": {
        "id": "AZIA70irj7tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = spark.read.parquet(\"/content/YelpChi_cut5\")\n",
        "predicted_df = df2.withColumn(\"predictions\", predict_udf(df2[\"data_grouped\"]))"
      ],
      "metadata": {
        "id": "gNM5pPagNTF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6qYDCEXNeOM",
        "outputId": "4f6dab97-14c9-4678-c708-bfba92370a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n",
            "|group_id|        data_grouped|\n",
            "+--------+--------------------+\n",
            "|       0|[35042, 27485, 16...|\n",
            "|       1|[38716, 18519, 88...|\n",
            "|       2|[41976, 1413, 169...|\n",
            "|       3|[41349, 8917, 293...|\n",
            "|       4|[110, 24197, 2344...|\n",
            "+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_df.show(5)"
      ],
      "metadata": {
        "id": "H70tal6ZTgeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f1ad70-aafe-4675-908d-7f802a5d17fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+---------------+\n",
            "|group_id|        data_grouped|    predictions|\n",
            "+--------+--------------------+---------------+\n",
            "|       0|[35042, 27485, 16...|[1, 0, 1, 0, 1]|\n",
            "|       1|[38716, 18519, 88...|[0, 1, 0, 1, 1]|\n",
            "|       2|[41976, 1413, 169...|[1, 1, 0, 0, 1]|\n",
            "|       3|[41349, 8917, 293...|[0, 0, 1, 1, 0]|\n",
            "|       4|[110, 24197, 2344...|[0, 0, 0, 0, 0]|\n",
            "+--------+--------------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predicted_df.write.mode(\"overwrite\").parquet(\"/content/drive/MyDrive/DOAN/predictions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhLjw2Vjk88i",
        "outputId": "c5db9de8-d0de-422f-f74c-b6a70672d97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 203 ms, sys: 32.7 ms, total: 235 ms\n",
            "Wall time: 47.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_exploded = predicted_df.withColumn('idx_node', explode(predicted_df['data_grouped']))"
      ],
      "metadata": {
        "id": "pD8K8R-GnSBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_exploded1 = predicted_df.withColumn('prediction', explode(predicted_df['predictions']))"
      ],
      "metadata": {
        "id": "q6HnA5Fvpcjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "from pyspark.sql.functions import row_number\n",
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "hOwZ_vGfnXuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "windowSpec = Window.orderBy(monotonically_increasing_id())\n",
        "df_exploded_idx = df_exploded.withColumn(\"row_number\", row_number().over(windowSpec))\n",
        "df_exploded_idx.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3-Jkl8Qt2H-",
        "outputId": "476c2719-7381-435f-b74c-a5ee6fd88140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+---------------+--------+----------+\n",
            "|group_id|        data_grouped|    predictions|idx_node|row_number|\n",
            "+--------+--------------------+---------------+--------+----------+\n",
            "|       0|[35042, 27485, 16...|[1, 0, 1, 0, 1]|   35042|         1|\n",
            "|       0|[35042, 27485, 16...|[1, 0, 1, 0, 1]|   27485|         2|\n",
            "|       0|[35042, 27485, 16...|[1, 0, 1, 0, 1]|   16164|         3|\n",
            "|       0|[35042, 27485, 16...|[1, 0, 1, 0, 1]|   21204|         4|\n",
            "|       0|[35042, 27485, 16...|[1, 0, 1, 0, 1]|   12201|         5|\n",
            "+--------+--------------------+---------------+--------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_exploded1_idx = df_exploded1.withColumn(\"row_number\", row_number().over(windowSpec))\n",
        "df_exploded1_idx.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj49I4C_tuFk",
        "outputId": "7de05fa4-e69e-473a-e154-622028c7baae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+---------------+----------+----------+\n",
            "|group_id|        data_grouped|    predictions|prediction|row_number|\n",
            "+--------+--------------------+---------------+----------+----------+\n",
            "|       0|[35042, 27485, 16...|[1, 0, 1, 0, 1]|         1|         1|\n",
            "|       0|[35042, 27485, 16...|[1, 0, 1, 0, 1]|         0|         2|\n",
            "|       0|[35042, 27485, 16...|[1, 0, 1, 0, 1]|         1|         3|\n",
            "|       0|[35042, 27485, 16...|[1, 0, 1, 0, 1]|         0|         4|\n",
            "|       0|[35042, 27485, 16...|[1, 0, 1, 0, 1]|         1|         5|\n",
            "+--------+--------------------+---------------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df = df_exploded1_idx.join(df_exploded_idx, on=\"row_number\", how=\"inner\")"
      ],
      "metadata": {
        "id": "lX2AeXi8uaDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_select = joined_df.select(\"idx_node\", \"prediction\")\n",
        "df_select.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlwoSdmlvnxM",
        "outputId": "78e31121-13c7-436c-f999-a687539580c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+\n",
            "|idx_node|prediction|\n",
            "+--------+----------+\n",
            "|   35042|         1|\n",
            "|   27485|         0|\n",
            "|   16164|         1|\n",
            "|   21204|         0|\n",
            "|   12201|         1|\n",
            "+--------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hK7uv0dcruJo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "8I7kE9IvUZc7",
        "nbT_33esyIw9",
        "EoIIV972T-ly",
        "PD-2a9PnRu9Y",
        "oxE_rzeIiwHM"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}